{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "#from io import StringIOrequests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.27.1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpr_pattern = re.compile(r'(\\d{2})(\\d{2})(\\d{2})[-]?(\\d{4})')\n",
    "\n",
    "# Example usage:\n",
    "cpr_number_1 = '0102031234'\n",
    "cpr_number_2 = '010203-1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1!\n",
      "Test 1 groups: ('01', '02', '03', '1234')\n",
      "DD: 01, MM: 02, YY: 03, IIII: 1234\n",
      "Test 2!\n",
      "DD: 01, MM: 02, YY: 03, IIII: 1234\n"
     ]
    }
   ],
   "source": [
    "test_1 = cpr_pattern.match(cpr_number_1)\n",
    "test_2 = cpr_pattern.match(cpr_number_2)\n",
    "\n",
    "if test_1:\n",
    "    print(\"Test 1!\")\n",
    "    print(\"Test 1 groups:\", test_1.groups())\n",
    "    day, month, year, identifier = test_1.groups()\n",
    "    print(f\"DD: {day}, MM: {month}, YY: {year}, IIII: {identifier}\")\n",
    "\n",
    "if test_2:\n",
    "    print(\"Test 2!\")\n",
    "    day, month, year, identifier = test_2.groups()\n",
    "    print(f\"DD: {day}, MM: {month}, YY: {year}, IIII: {identifier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person was born in the 1800s.\n"
     ]
    }
   ],
   "source": [
    "def cpr_century(cpr):\n",
    "    cpr_pattern = re.compile(r'(\\d{2})(\\d{2})(\\d{2})[-]?(\\d{4})')\n",
    "    match = cpr_pattern.match(cpr)\n",
    "\n",
    "    if match:\n",
    "        day, month, year, identifier = match.groups()\n",
    "        identifier = int(identifier)\n",
    "        year = int(year)\n",
    "\n",
    "        if 1 <= identifier <= 3999:\n",
    "            century = 1900 + year // 100\n",
    "        elif 4000 <= identifier <= 4999 and 0 <= year <= 36:\n",
    "            century = 2000 + year // 100\n",
    "        elif 4000 <= identifier <= 4999 and 37 <= year <= 99:\n",
    "            century = 1900 + year // 100\n",
    "        elif 5000 <= identifier <= 8999 and 0 <= year <= 57:\n",
    "            century = 2000 + year // 100\n",
    "        elif 5000 <= identifier <= 8999 and 58 <= year <= 99:\n",
    "            century = 1800 + year // 100\n",
    "        elif 9000 <= identifier <= 9999 and 0 <= year <= 36:\n",
    "            century = 2000 + year // 100\n",
    "        elif 9000 <= identifier <= 9999 and 37 <= year <= 99:\n",
    "            century = 1900 + year // 100\n",
    "        else:\n",
    "            raise ValueError(\"Invalid identifier or year range\")\n",
    "        \n",
    "        return century\n",
    "    else:\n",
    "        raise ValueError(\"Invalid CPR format\")\n",
    "\n",
    "cpr_number = '2201978999'\n",
    "try:\n",
    "    result = cpr_century(cpr_number)\n",
    "    print(f\"The person was born in the {result}s.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpr_lst = ['220197-8989', '2201650099', '121201-0976', '1224230973', '010124-9001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPR:220197-8989 is born in the 1800\n",
      "CPR:2201650099 is born in the 1900\n",
      "CPR:121201-0976 is born in the 1900\n",
      "CPR:1224230973 is born in the 1900\n",
      "CPR:010124-9001 is born in the 2000\n"
     ]
    }
   ],
   "source": [
    "for cpr in cpr_lst:\n",
    "    result = cpr_century(cpr)\n",
    "    print(fr'CPR:{cpr} is born in the {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CSV file\n",
    "url = 'https://raw.githubusercontent.com/several27/FakeNewsCorpus/master/news_sample.csv'\n",
    "\n",
    "# Fetching the content from the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Checking if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Reading CSV data using pandas\n",
    "    csv_data = StringIO(response.text)\n",
    "    df = pd.read_csv(csv_data)\n",
    "\n",
    "    # Displaying the first few rows of the DataFrame\n",
    "    #print(df.head())\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        250 non-null    int64  \n",
      " 1   id                250 non-null    int64  \n",
      " 2   domain            250 non-null    object \n",
      " 3   type              238 non-null    object \n",
      " 4   url               250 non-null    object \n",
      " 5   content           250 non-null    object \n",
      " 6   scraped_at        250 non-null    object \n",
      " 7   inserted_at       250 non-null    object \n",
      " 8   updated_at        250 non-null    object \n",
      " 9   title             250 non-null    object \n",
      " 10  authors           170 non-null    object \n",
      " 11  keywords          0 non-null      float64\n",
      " 12  meta_keywords     250 non-null    object \n",
      " 13  meta_description  54 non-null     object \n",
      " 14  tags              27 non-null     object \n",
      " 15  summary           0 non-null      float64\n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There a multiple all null columns. #11 and #15\n",
    "\n",
    "\n",
    "Missing Values:\n",
    "\n",
    "The 'authors', 'keywords', 'meta_keywords', 'meta_description', and 'tags' columns contain empty lists ('[]'), which may imply missing or incomplete information. You may need to handle or investigate these cases.\n",
    "Date Representation:\n",
    "\n",
    "The 'scraped_at', 'inserted_at', and 'updated_at' columns seem to contain timestamp values. Ensure that these columns are correctly parsed as datetime objects if you plan to perform temporal analysis.\n",
    "Text Data Cleaning:\n",
    "\n",
    "The 'content' column contains HTML tags, line breaks, and special characters. Depending on your analysis, you might want to clean or preprocess the text data to remove HTML tags and unnecessary characters.\n",
    "Categorical Values:\n",
    "\n",
    "The 'type' column appears to categorize news into 'unreliable' and 'fake.' Ensure that these categories are well-defined and consistent throughout the dataset.\n",
    "Column Names:\n",
    "\n",
    "Some column names contain spaces, which might cause inconvenience in handling them. You might consider renaming columns for ease of use.\n",
    "Encoding Issues:\n",
    "\n",
    "Check for any encoding issues in the text data, especially if the content includes non-ASCII characters. Ensure that the text is encoded properly.\n",
    "Duplicate Titles:\n",
    "\n",
    "Ensure that the 'title' column does not contain duplicate entries, as each news article should have a unique title.\n",
    "Column Data Types:\n",
    "\n",
    "Confirm that each column has the correct data type. For example, 'type' might be categorical, 'scraped_at,' 'inserted_at,' and 'updated_at' should be datetime, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore unique values in categorical columns\n",
    "# for column in df.select_dtypes(include='object').columns:\n",
    "    # print(f\"Unique values in {column}: {df[column].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    cleaned_text = raw_text.lower()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "   cleaned_text = re.sub(r'\\s+', ' ', raw_text)\n",
    "\n",
    "    # Replace uppercase letters with lowercase\n",
    "   cleaned_text = re.sub(r'[A-Z]', lambda match: match.group().lower(), cleaned_text)\n",
    "   \n",
    "   cleaned_text = re.sub(r'\\b\\d+\\b', '<NUM>', cleaned_text)\n",
    "   cleaned_text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '<EMAIL>', cleaned_text)\n",
    "   cleaned_text = re.sub(r'https?://\\S+', '<URL>', cleaned_text)\n",
    "   cleaned_text = re.sub(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', '<DATE>', cleaned_text)\n",
    "\n",
    "\n",
    "   return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      sometimes the power of christmas will make you...\n",
       "1      awakening of <NUM> strands of dna – “reconnect...\n",
       "2      never hike alone: a friday the 13th fan film u...\n",
       "3      when a rare shark was caught, scientists were ...\n",
       "4      donald trump has the unnerving ability to abil...\n",
       "                             ...                        \n",
       "245    prison for rahm, god’s work and many others he...\n",
       "246    <NUM> useful items for your tiny home headline...\n",
       "247    former cia director michael hayden said thursd...\n",
       "248    antonio sabato jr. says hollywood's liberal el...\n",
       "249    former u.s. president bill clinton on monday c...\n",
       "Name: content, Length: 250, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
